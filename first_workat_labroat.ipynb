{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNg10qa6NDjrJNpHFC6vbIn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Womics/lab_rotation/blob/main/first_workat_labroat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_AwozOJmS0e",
        "outputId": "36280e02-a721-4d0f-96a3-91f363136de1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 4, 27]),\n",
              " array([0.8, 0.2]),\n",
              " array([4, 6]),\n",
              " array([[ 1, -1],\n",
              "        [ 0,  0]]),\n",
              " array([[0.08189437, 0.24319524],\n",
              "        [0.17585916, 0.28639048]])]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Equivalent of vPow in estimation function.C++\n",
        "def vPow(base, exp):\n",
        "    return np.power(base, exp)\n",
        "\n",
        "# Equivalent of ZeroOne in estimation function.C++\n",
        "def ZeroOne(x):\n",
        "    return 1 - x\n",
        "\n",
        "# Equivalent of ColSums_cpp in C++\n",
        "def ColSums_cpp(X):\n",
        "    return np.sum(X, axis=0)\n",
        "\n",
        "# Equivalent of Pruning_cpp in C++\n",
        "def Pruning_cpp(West, z):\n",
        "    n = West.shape[1]\n",
        "    for j in range(n):\n",
        "        if z[j] == 1:\n",
        "            West[:, j][West[:, j] < 0] = 0\n",
        "        elif z[j] == 0:\n",
        "            West[:, j][West[:, j] > 0] = 0\n",
        "    return West\n",
        "\n",
        "# Equivalent of EstimateConnections_cpp in C++\n",
        "def EstimateConnections_cpp(Lambda, Eta, nitr):\n",
        "    n = Lambda.shape[1]\n",
        "    I = np.eye(n)\n",
        "    Theta = np.random.rand(n, n)\n",
        "    np.fill_diagonal(Theta, 0)\n",
        "\n",
        "    for itr in range(nitr):\n",
        "      # step1\n",
        "        West = Lambda @ (I - Theta)\n",
        "        #step2\n",
        "        for i in range(n):\n",
        "            for j in range(n):\n",
        "                Theta[i, j] = norm.cdf(West[i, j] + Eta[i, j])\n",
        "        np.fill_diagonal(Theta, 0)\n",
        "        #step3\n",
        "        LT = Lambda @ Theta\n",
        "        Lambda = Lambda - np.diag(np.diag(Lambda)) + np.diag(np.diag(LT))\n",
        "    return West\n",
        "\n",
        "# Displaying the defined functions to ensure they are correctly defined\n",
        "[vPow(np.array([2, 3]), np.array([2, 3])),\n",
        " ZeroOne(np.array([0.2, 0.8])),\n",
        " ColSums_cpp(np.array([[1, 2], [3, 4]])),\n",
        " Pruning_cpp(np.array([[1, -1], [-1, 1]]), np.array([1, 0])),\n",
        " EstimateConnections_cpp(np.array([[0.1, 0.3], [0.2, 0.4]]), np.array([[0.05, 0.07], [0.02, 0.06]]), 1)]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def EstimateConnectionsWithLabel_cpp(Lambda, Eta, z, nitr):\n",
        "    n = Lambda.shape[1]\n",
        "    I = np.eye(n)\n",
        "    Theta = np.random.rand(n, n)\n",
        "    np.fill_diagonal(Theta, 0)\n",
        "    West = np.zeros((n, n))\n",
        "\n",
        "    for _ in range(nitr):\n",
        "        # Step 1\n",
        "        West = Lambda @ (I - Theta)\n",
        "\n",
        "        # Step 2\n",
        "        West = Pruning_cpp(West, z)\n",
        "\n",
        "        # Step 3\n",
        "        for i in range(n):\n",
        "            for j in range(n):\n",
        "                Theta[i, j] = norm.cdf(West[i, j] + Eta[i, j])\n",
        "        np.fill_diagonal(Theta, 0)\n",
        "\n",
        "        # Step 4\n",
        "        LT = Lambda @ Theta\n",
        "        Lambda = Lambda - np.diag(np.diag(Lambda)) + np.diag(np.diag(LT))\n",
        "\n",
        "    return West\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "def likelihood_cpp(Lambda, Eta, z, nitr):\n",
        "    n = Lambda.shape[1]\n",
        "    I = np.eye(n)\n",
        "    Theta = np.zeros((n, n))\n",
        "    West = EstimateConnectionsWithLabel_cpp(Lambda, Eta, z, nitr)\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            Theta[i, j] = norm.cdf(West[i, j] + Eta[i, j])\n",
        "\n",
        "    LT = Lambda @ Theta\n",
        "    Lambda = Lambda - np.diag(np.diag(Lambda)) + np.diag(np.diag(LT))\n",
        "    Error = Lambda - West @ np.linalg.inv(I - Theta)\n",
        "\n",
        "    like = 1\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            if Lambda[i, j] < 0:\n",
        "                continue\n",
        "            else:\n",
        "                like *= norm.pdf(Error[i, j], 0, np.sqrt(0.15))\n",
        "\n",
        "    return like\n",
        "\n",
        "def gibbs_cpp(Lambda, Eta, alpha, z, ind):\n",
        "    z1 = z.copy()\n",
        "    z0 = z.copy()\n",
        "    z1[ind] = 1\n",
        "    z0[ind] = 0\n",
        "\n",
        "    like1 = likelihood_cpp(Lambda, Eta, z1, 10)\n",
        "    like0 = likelihood_cpp(Lambda, Eta, z0, 10)\n",
        "    fact1 = np.prod(vPow(alpha, z1) * vPow(1 - alpha, 1 - z1))\n",
        "    fact0 = np.prod(vPow(alpha, z0) * vPow(1 - alpha, 1 - z0))\n",
        "\n",
        "    prob = (like1 * fact1) / (like1 * fact1 + like0 * fact0)\n",
        "    rand = np.random.uniform(0, 1)\n",
        "    return 1 if rand < prob else 0\n",
        "\n",
        "def remove_elem(x, idx):\n",
        "    return np.delete(x, idx)\n",
        "\n",
        "def sigmoid_cpp(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sample_z_cpp(n):\n",
        "    return np.random.choice([0, 1], size=n, p=[0.5, 0.5])\n",
        "\n",
        "def rbinom_cpp(n, beta):\n",
        "    return np.random.binomial(1, beta, n)\n"
      ],
      "metadata": {
        "id": "-klgfyDgCb-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def estimate_excitatory_probabilities_mproj_cpp(Lambda, Eta, States, nitr_em):\n",
        "    n = Lambda.shape[1]\n",
        "    nstate = States.shape[0]\n",
        "    eps = 1e-5\n",
        "\n",
        "    alpha = np.full(n, 0.5)\n",
        "    beta = np.zeros(n)\n",
        "    pre_alpha = alpha.copy()\n",
        "    p = np.zeros(nstate)\n",
        "    q = np.zeros(nstate)\n",
        "\n",
        "    for itr in range(nitr_em):\n",
        "        for i in range(nstate):\n",
        "            state = States[i, :]\n",
        "            like = likelihood_cpp(Lambda, Eta, state, 10)\n",
        "            fact = np.prod(np.power(alpha, state) * np.power(1 - alpha, 1 - state))\n",
        "            p[i] = like * fact\n",
        "        p /= p.sum()\n",
        "\n",
        "        for j in range(n):\n",
        "            beta[j] = np.sum(States[:, j] * p)\n",
        "\n",
        "        for i in range(nstate):\n",
        "            state = States[i, :]\n",
        "            q[i] = np.prod(np.power(beta, state) * np.power(1 - beta, 1 - state))\n",
        "\n",
        "        for j in range(n):\n",
        "            alpha[j] = np.sum(States[:, j] * q)\n",
        "\n",
        "        vec_error = alpha - pre_alpha\n",
        "        error = np.linalg.norm(vec_error)\n",
        "        if error < eps:\n",
        "            break\n",
        "        else:\n",
        "            pre_alpha = alpha.copy()\n",
        "\n",
        "    return alpha\n"
      ],
      "metadata": {
        "id": "itJw8wDrDQm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "def estimate_excitatory_probabilities_eproj_cpp(Lambda, Eta, States, nitr_em):\n",
        "    n = Lambda.shape[1]\n",
        "    nstate = States.shape[0]\n",
        "    eps = 1e-16\n",
        "\n",
        "    alpha = np.full(n, 0.5)\n",
        "    beta = np.full(n, 0.5)\n",
        "    pre_alpha = alpha.copy()\n",
        "    C = np.zeros((nstate, n))\n",
        "\n",
        "    for itr in range(nitr_em):\n",
        "        for i in range(nstate):\n",
        "            state = States[i, :]\n",
        "            for j in range(n):\n",
        "                estate = np.delete(state, j)\n",
        "                ebeta = np.delete(beta, j)\n",
        "                B = np.prod(np.power(ebeta, estate) * np.power(1 - ebeta, 1 - estate))\n",
        "                z1 = state.copy()\n",
        "                z0 = state.copy()\n",
        "                z1[j] = 1\n",
        "                z0[j] = 0\n",
        "                like1 = likelihood_cpp(Lambda, Eta, z1, 5)\n",
        "                like0 = likelihood_cpp(Lambda, Eta, z0, 5)\n",
        "                fact1 = np.prod(np.power(alpha, z1) * np.power(1 - alpha, 1 - z1))\n",
        "                fact0 = np.prod(np.power(alpha, z0) * np.power(1 - alpha, 1 - z0))\n",
        "                A = np.log(like1 + fact1) - np.log(like0 + fact0)\n",
        "                C[i, j] = B * A\n",
        "        a = C.sum(axis=0)\n",
        "        beta = sigmoid(a)\n",
        "\n",
        "        # Update probabilities q\n",
        "        q = np.array([np.prod(np.power(beta, States[i, :]) * np.power(1 - beta, 1 - States[i, :])) for i in range(nstate)])\n",
        "\n",
        "        # Update alpha\n",
        "        alpha = np.array([np.sum(States[:, j] * q) for j in range(n)])\n",
        "\n",
        "        # Check convergence\n",
        "        if np.linalg.norm(alpha - pre_alpha) < 1e-3:\n",
        "            break\n",
        "        pre_alpha = alpha.copy()\n",
        "\n",
        "    return alpha\n"
      ],
      "metadata": {
        "id": "MYsKt-VcDoke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_excitatory_probabilities_mproj_gibbs_cpp(Lambda, Eta, nitr_em, nsamp, excl_ratio):\n",
        "    n = Lambda.shape[1]\n",
        "    nexcl = int(round(nsamp * excl_ratio))\n",
        "    ngibbs = nsamp - nexcl\n",
        "    eps = 1e-5\n",
        "\n",
        "    alpha = np.full(n, 0.5)\n",
        "    pre_alpha = alpha.copy()\n",
        "    Z1 = np.zeros((nsamp, n))\n",
        "\n",
        "    for itr in range(nitr_em):\n",
        "        if itr == 1:\n",
        "            samp_z = sample_z_cpp(n)\n",
        "        for i in range(nsamp):\n",
        "            for j in range(n):\n",
        "                samp_z[j] = gibbs_cpp(Lambda, Eta, alpha, samp_z, j)\n",
        "            Z1[i, :] = samp_z.copy()\n",
        "\n",
        "        subZ1 = Z1[nexcl:, :]\n",
        "        beta = subZ1.mean(axis=0)\n",
        "\n",
        "        for i in range(nsamp):\n",
        "            samp_z = np.random.binomial(1, beta)\n",
        "            Z2[i, :] = samp_z\n",
        "\n",
        "        alpha = Z2.mean(axis=0)\n",
        "\n",
        "        if np.linalg.norm(alpha - pre_alpha) < eps:\n",
        "            break\n",
        "        pre_alpha = alpha.copy()\n",
        "\n",
        "    return alpha\n"
      ],
      "metadata": {
        "id": "PtsmwJrGDrNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm, binom\n",
        "from numpy.linalg import norm as np_norm\n",
        "\n",
        "def estimate_excitatory_probabilities_eproj_gibbs_cpp(Lambda, Eta, nitr_em, nsamp, excl_ratio):\n",
        "    n = Lambda.shape[1]\n",
        "    nexcl = round(nsamp * excl_ratio)\n",
        "    ngibbs = nsamp - nexcl\n",
        "    eps = 1e-16\n",
        "\n",
        "    Z1 = np.zeros((nsamp, n))\n",
        "    Z2 = np.zeros((nsamp, n))\n",
        "    subZ1 = np.zeros((ngibbs, n))\n",
        "    alpha = np.full(n, 0.5)\n",
        "    beta = np.full(n, 0.5)\n",
        "    pre_alpha = alpha.copy()\n",
        "    C = np.zeros((ngibbs, n))\n",
        "\n",
        "    for itr in range(nitr_em):\n",
        "        if itr == 1:\n",
        "            samp_z = sample_z_cpp(n)\n",
        "        for i in range(nsamp):\n",
        "            for j in range(n):\n",
        "                samp_z[j] = gibbs_cpp(Lambda, Eta, alpha, samp_z, j)\n",
        "            Z1[i, :] = samp_z.copy()\n",
        "\n",
        "        subZ1 = Z1[nexcl:, :]\n",
        "\n",
        "        for i in range(ngibbs):\n",
        "            state = subZ1[i, :]\n",
        "            for j in range(n):\n",
        "                estate = np.delete(state, j)\n",
        "                ebeta = np.delete(beta, j)\n",
        "                z1 = state.copy()\n",
        "                z0 = state.copy()\n",
        "                z1[j] = 1\n",
        "                z0[j] = 0\n",
        "                like1 = likelihood_cpp(Lambda, Eta, z1, 5)\n",
        "                like0 = likelihood_cpp(Lambda, Eta, z0, 5)\n",
        "                fact1 = np.prod(np.power(alpha, z1) * np.power(1 - alpha, 1 - z1))\n",
        "                fact0 = np.prod(np.power(alpha, z0) * np.power(1 - alpha, 1 - z0))\n",
        "                p1 = like1 * fact1\n",
        "                p0 = like0 * fact0\n",
        "                if p1 == 0:\n",
        "                    p1 = eps\n",
        "                if p0 == 0:\n",
        "                    p0 = eps\n",
        "\n",
        "                C[i, j] = np.log(p1) - np.log(p0)\n",
        "\n",
        "        a = C.sum(axis=0) / ngibbs\n",
        "        beta = 1 / (1 + np.exp(-a))\n",
        "\n",
        "        for i in range(nsamp):\n",
        "            samp_z = binom.rvs(1, beta)\n",
        "            Z2[i, :] = samp_z\n",
        "\n",
        "        alpha = Z2.mean(axis=0)\n",
        "\n",
        "        vec_error = alpha - pre_alpha\n",
        "        error = np_norm(vec_error)\n",
        "        if error < 1e-3:\n",
        "            break\n",
        "        pre_alpha = alpha.copy()\n",
        "\n",
        "    return alpha\n"
      ],
      "metadata": {
        "id": "54bhdvQID7-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpDXMEIMo2O7",
        "outputId": "4e12f620-c9a7-40bd-b207-a25642b9357b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **estimating function.Rの内容をpythonに変換**\n"
      ],
      "metadata": {
        "id": "ONQnbl6bFvlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm\n",
        "from scipy.special import erfinv\n",
        "\n",
        "def calculate_pre_spike(data, pre_period, post_period):\n",
        "    L = data.shape[1]  # observed time\n",
        "    if pre_period == 1:\n",
        "        pre_spike = data[:, :L - post_period]\n",
        "    else:\n",
        "        pre_tmp = data[:, :L - post_period].T\n",
        "        pre_spike = np.convolve(pre_tmp.flatten(), np.ones(pre_period), mode='valid').reshape(pre_tmp.shape)\n",
        "        pre_spike[pre_spike > 0] = 1\n",
        "        pre_spike = pre_spike.T\n",
        "    return pre_spike\n",
        "\n",
        "def calculate_post_spike(data, pre_period, post_period):\n",
        "    L = data.shape[1]  # observed time\n",
        "    if post_period == 1:\n",
        "        post_spike = data[:, pre_period:L]\n",
        "    else:\n",
        "        post_tmp = data[:, pre_period:L].T\n",
        "        post_spike = np.convolve(post_tmp.flatten(), np.ones(post_period), mode='valid').reshape(post_tmp.shape)\n",
        "        post_spike[post_spike > 0] = 1\n",
        "        post_spike = post_spike.T\n",
        "    return post_spike\n",
        "\n",
        "def probit(p):\n",
        "    return np.sqrt(2) * erfinv(2 * p - 1)\n",
        "\n",
        "def calculate_spike_prob_matrix(pre_spike, post_spike, nclust):\n",
        "    L = post_spike.shape[1]\n",
        "    N = post_spike.shape[0]\n",
        "\n",
        "    firing_sum = np.sum(pre_spike, axis=1)\n",
        "    prob_fire = np.zeros((N, N))\n",
        "    prob_rest = np.zeros((N, N))\n",
        "\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            Sj = pre_spike[i, :]\n",
        "            Si = post_spike[j, :]\n",
        "            S_sum = Si + Sj\n",
        "            S_dif = Si - Sj\n",
        "            prob_fire[i, j] = np.sum(S_sum == 2) / firing_sum[i]\n",
        "            prob_rest[i, j] = np.sum(S_dif == 1) / (L - firing_sum[i])\n",
        "\n",
        "    prob_fire[prob_fire == 0] = np.finfo(float).eps\n",
        "    prob_rest[prob_rest == 0] = np.finfo(float).eps\n",
        "\n",
        "    array_prob = np.zeros((N, N, 2))\n",
        "    array_prob[:, :, 0] = prob_fire\n",
        "    array_prob[:, :, 1] = prob_rest\n",
        "\n",
        "    return array_prob\n",
        "\n",
        "def estimate_pseudo_connections(prob_fire, prob_rest):\n",
        "    return np.apply_along_axis(probit, 2, prob_fire) - np.apply_along_axis(probit, 2, prob_rest)\n",
        "\n",
        "def estimate_connections(Lambda, Eta, z, param):\n",
        "    N = Lambda.shape[0]\n",
        "    if z is None:\n",
        "        West = estimate_connections_cpp(Lambda, Eta, param['number_of_iteration'])\n",
        "    else:\n",
        "        West = estimate_connections_with_label_cpp(Lambda, Eta, z, param['number_of_iteration'])\n",
        "    return West\n",
        "\n",
        "def estimate_excitatory_label(Lambda, Eta, proj_type, param):\n",
        "    N = Lambda.shape[1]\n",
        "    nitr_em = param['number_of_EM_iteration']\n",
        "    thr = param['excitatory_threshold']\n",
        "\n",
        "    if proj_type == 'e':\n",
        "        alpha = estimate_excitatory_probabilities_eproj_cpp(Lambda, Eta, nitr_em)\n",
        "    elif proj_type == 'm':\n",
        "        alpha = estimate_excitatory_probabilities_mproj_cpp(Lambda, Eta, nitr_em)\n",
        "\n",
        "    z = (alpha > thr).astype(int)\n",
        "    return z\n",
        "\n",
        "def estimate_excitatory_label_gibbs(Lambda, Eta, proj_type, param):\n",
        "    N = Lambda.shape[1]\n",
        "    nalpha = param['number_of_alpha']\n",
        "    nsamp = param['number_of_Gibbs_sampler']\n",
        "    excl_ratio = param['gibbs_exclude_ratio']\n",
        "\n",
        "    Alphas = []\n",
        "    if proj_type == 'e':\n",
        "        for i in range(nalpha):\n",
        "            alpha = estimate_excitatory_probabilities_eproj_gibbs_cpp(Lambda, Eta, param['number_of_EM_iteration'], nsamp, excl_ratio)\n",
        "            Alphas.append(alpha)\n",
        "    elif proj_type == 'm':\n",
        "        for i in range(nalpha):\n",
        "            alpha = estimate_excitatory_probabilities_mproj_gibbs_cpp(Lambda, Eta, param['number_of_EM_iteration'], nsamp, excl_ratio)\n",
        "            Alphas.append(alpha)\n",
        "\n",
        "    z = (np.mean(Alphas, axis=0) != 1).astype(int)\n",
        "    return z\n"
      ],
      "metadata": {
        "id": "WFX4rFQcmbBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **main.Rをpythonで書き直す**"
      ],
      "metadata": {
        "id": "J6TqwB-nH1tH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set parameters\n",
        "pre_period = 10\n",
        "post_period = 1\n",
        "\n",
        "params = {\n",
        "    \"excitatory_threshold\": 0.5,\n",
        "    \"number_of_iteration\": 10,\n",
        "    \"number_of_EM_iteration\": 50,\n",
        "    \"number_of_cluster\": 10,\n",
        "    \"number_of_alpha\": 10,\n",
        "    \"number_of_Gibbs_sampler\": 100,\n",
        "    \"gibbs_exclude_ratio\": 0.02\n",
        "}\n",
        "\n",
        "print(\"Reading data...\")\n",
        "data = pd.read_pickle(filepath)  # Assuming the data file is a pickle for Python compatibility\n",
        "\n",
        "print(\"Preprocessing spikes...\")\n",
        "pre_spike = calculate_pre_spike(data, pre_period, post_period)\n",
        "post_spike = calculate_post_spike(data, pre_period, post_period)\n",
        "\n",
        "array_prob = calculate_spike_prob_matrix(pre_spike, post_spike, params['number_of_cluster'])\n",
        "prob_fire = array_prob[:, :, 0]\n",
        "prob_rest = array_prob[:, :, 1]\n",
        "del pre_spike, post_spike  # free memory\n",
        "\n",
        "Lambda = estimate_pseudo_connections(prob_fire, prob_rest)\n",
        "Eta = np.apply_along_axis(probit, 2, prob_rest)\n",
        "del prob_fire, prob_rest  # free memory\n",
        "\n",
        "print(\"Estimating excitatory label...\")\n",
        "z = estimate_excitatory_label_gibbs(Lambda, Eta, \"e\", params)\n",
        "\n",
        "print(\"Estimating neural connections...\")\n",
        "West = estimate_connections(Lambda, Eta, z, params)\n",
        "print(\"-> done.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "7eVkt7ZSoyCT",
        "outputId": "b532886b-8d2d-4433-fad7-5d8be234197d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading data...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'filepath' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-61525030e67b>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reading data...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Assuming the data file is a pickle for Python compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preprocessing spikes...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'filepath' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UrbWj4oqpHbh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}